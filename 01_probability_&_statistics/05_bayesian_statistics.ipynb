{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c3f99d",
   "metadata": {},
   "source": [
    "# 05 - Bayesian Statistics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d1f45",
   "metadata": {},
   "source": [
    "### **Motivation**\n",
    "When modelling a random variable, we assume it arises from a probability distribution with unknown parameters that must be estimated. In frequentist statistics, parameters are treated as fixed constants. That is, we assume there is one true value for each parameter, and our goal is to estimate that value from the data. The fundamental idea behind **Bayesian** statistics is that unknown parameters are treated as variable. Since they are variable, the parameters themselves can also be treated as random variables with their own probability distributions. Our goal then becomes to estimate the target by estimating the probability distribution of the random variables that the parameters of the target distribution follow. In other words, we quantify uncertainty about parameters using probability; we represent greater uncertainty about a parameter by greater variance in its distribution. \n",
    "\n",
    "For example, suppose we model the heights of all the buildings in the world as coming from a normal distribution with known variance $\\sigma^2$ but unknown mean $\\mu$. Under frequentist statistics we would estimate $\\mu$ directly (for instance, via the sample mean), however withh a Bayesian approach we assign a probability distribution to the parameter $\\mu$. For instance we could model $\\mu$ as another normal distribution $\\mu \\sim N(\\mu_{\\mu}, \\sigma^2_{\\mu})$ with unknown mean $\\mu_{\\mu}$ and unknown variance $\\sigma^2_{\\mu}$. Notice how we have two different normal distributions going on here: \n",
    "- One describing the data (the likelihood),\n",
    "- One describing our uncertainty about the parameter \n",
    "A smaller variance represents greater prior confidence; a larger variance represents greater uncertainty.\n",
    "\n",
    "Another feature of Bayesian statistics is that we update the estimates for the parameters using the observed data. We start with a **prior** distribution, incorporate data through the likelihood, and obtain an updated **posterior** distribution. We can make estimates for the distributions of the parameters with little or no data and update these estimates as new data is observed. This approach often works well in real world scenarios. For example, suppose we are trying to estimate the probability that Arsenal will win the Premier League. A frequentist apporach would require us to have many examples of identical seasons in order to generate an estimate. But previous seasons involve different teams, players, managers etc. so aren't really representative of what will happen this season. So we do not have directly comparable observations to draw from. Nevertheless, this prior information is informative in some way, albeit not directly. A Bayesian approach allows us to leverage information that may exist latently about a problem but not necessarily in the form of observed data. We can build a prior distribution which captures this information and update it as data becomes available (e.g. after each match). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaeb923",
   "metadata": {},
   "source": [
    "### **Bayes' Theorem**\n",
    "Bayes' Theorem is as follows:\n",
    "$\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(B|A)\\mathbb{P}(A)}{\\mathbb{P}(B)}$\n",
    "\n",
    "A quick proof:\n",
    "$\\frac{\\mathbb{P}(B|A)\\mathbb{P}(A)}{\\mathbb{P}(B)} = \\frac{\\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(A)}\\mathbb{P}(A)}{\\mathbb{P}(B)} = \\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(B)} = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)} = \\mathbb{P}(A|B)$\n",
    "\n",
    "We implement Bayes' theorem for estimation as:\n",
    "$\\mathbb{P}(\\theta|x) = \\frac{\\mathbb{P}(x|\\theta)\\mathbb{P}(\\theta)}{\\mathbb{P}(x)}$ \n",
    "where: \n",
    "- $\\theta$ is the parameter we seek to estimate\n",
    "- $x$ is the observed data\n",
    "\n",
    "So Bayes' Theorem relates:\n",
    "- The **posterior** distribution: $\\mathbb{P}(\\theta|x)$\n",
    "- The **prior** distribution $\\mathbb{P}(\\theta)$\n",
    "- The **likelihood** $\\mathbb{P}(x|\\theta)$\n",
    "- The **evidence** $\\mathbb{P}(x)$\n",
    "\n",
    "Note that $\\mathbb{P}(x)$ is a normalising constant which is unrelated to $\\theta$ so we often write:\n",
    "$\\mathbb{P}(\\theta|x) \\propto \\mathbb{P}(x|\\theta)\\mathbb{P}(\\theta)$ \n",
    "$\\mathbb{P}(x)$ exists to ensure the posterior is a valid probability distribution which integrates to 1 across all parameter values.  In practice it may not be able to be computed analytically so is usually estimated using computational methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd060f",
   "metadata": {},
   "source": [
    "### **Conjugate Priors**\n",
    "A conjugate prior is a prior which produces a posterior distribution of the same type. The table below shows some common examples of conjugate priors. \n",
    "\n",
    "| Likelihood | Prior (Conjugate) | Posterior |\n",
    "|------------|-------------------|-----------|\n",
    "| $X \\sim \\text{Binomial}(n,\\theta)$ | $\\theta \\sim \\text{Beta}(\\alpha,\\beta)$ | $\\theta \\mid x \\sim \\text{Beta}(\\alpha + k,\\; \\beta + n - k)$ |\n",
    "| $X \\sim \\text{Bernoulli}(\\theta)$ | $\\theta \\sim \\text{Beta}(\\alpha,\\beta)$ | $\\theta \\mid x \\sim \\text{Beta}(\\alpha + \\sum x_i,\\; \\beta + n - \\sum x_i)$ |\n",
    "| $X \\sim \\text{Poisson}(\\lambda)$ | $\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)$ | $\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + \\sum x_i,\\; \\beta + n)$ |\n",
    "| $X \\sim \\text{Exponential}(\\lambda)$ | $\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)$ | $\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n,\\; \\beta + \\sum x_i)$ |\n",
    "| $X \\sim N(\\mu,\\sigma^2)$ (known $\\sigma^2$) | $\\mu \\sim N(\\mu_0,\\tau^2)$ | $\\mu \\mid x \\sim N(\\mu_n,\\tau_n^2)$ |\n",
    "\n",
    "Notice how in each case, the posterior and prior distributions come from the same family. Proofs of these are beyond the scope of this resource.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0e474",
   "metadata": {},
   "source": [
    "### **Worked Example: Beta‚ÄìBinomial Conjugacy**\n",
    "Suppose we observe $k$ successes in $n$ Bernoulli trials:\n",
    "\n",
    "$$\n",
    "X \\mid \\theta \\sim \\text{Binomial}(n,\\theta)\n",
    "$$\n",
    "\n",
    "The likelihood is:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X = k \\mid \\theta)\n",
    "=\n",
    "\\binom{n}{k}\\theta^k (1-\\theta)^{n-k}\n",
    "$$\n",
    "\n",
    "Assume a Beta prior:\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Beta}(\\alpha,\\beta)\n",
    "$$\n",
    "\n",
    "with density\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\theta)\n",
    "=\n",
    "\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\n",
    "\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\theta \\mid X=k)\n",
    "\\propto\n",
    "\\mathbb{P}(X=k \\mid \\theta)\\mathbb{P}(\\theta)\n",
    "$$\n",
    "\n",
    "Substitute likelihood and prior:\n",
    "\n",
    "$$\n",
    "\\propto\n",
    "\\left[\\binom{n}{k}\\theta^k (1-\\theta)^{n-k}\\right]\n",
    "\\left[\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\right]\n",
    "$$\n",
    "\n",
    "Ignore constants that do not depend on $\\theta$:\n",
    "\n",
    "$$\n",
    "\\propto\n",
    "\\theta^{k+\\alpha-1}\n",
    "(1-\\theta)^{n-k+\\beta-1}\n",
    "$$\n",
    "\n",
    "\n",
    "This has the same functional form as a Beta distribution\n",
    "\n",
    "$$\n",
    "\\theta \\mid X=k\n",
    "\\sim\n",
    "\\text{Beta}(\\alpha + k,\\; \\beta + n - k)\n",
    "$$\n",
    "\n",
    "The posterior parameters are:\n",
    "\n",
    "$$\n",
    "\\alpha_{\\text{post}} = \\alpha + k\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_{\\text{post}} = \\beta + n - k\n",
    "$$\n",
    "\n",
    "So suppose we say $k=72$ successes in $n=100$ trials, and our initial prior was \n",
    "$$\n",
    "\\theta \\sim \\text{Beta}(\\alpha=0,\\beta=0)\n",
    "$$\n",
    "\n",
    "Then our posterior distribution is\n",
    "$$\n",
    "\\theta \\sim \\text{Beta}(\\alpha=72,\\beta=28)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9e4a3",
   "metadata": {},
   "source": [
    "### **Markov Chains**\n",
    "**Markov Chains** are an important part of the next section so they are discussed here first. \n",
    "\n",
    "A Markov chain is a sequence of random variables $\\theta_0, \\theta_1, \\theta_2, \\cdots$ with the Markov property:\n",
    "$\\mathbb{P}(\\theta_{t+1}|\\theta_t, \\theta_t-1, \\cdots, \\theta_0) = \\mathbb{P}(\\theta_{t+1}|\\theta_t)$\n",
    "\n",
    "The Markov property is called memorylessness; the future depends only on the present, not on the past\n",
    "\n",
    "The **transition kernel** $K(\\theta '|\\theta)$ is the probability of moving from one state to the next \n",
    "\n",
    "A distribution $\\pi(\\theta)$ is **stationary** if \n",
    "\n",
    "$$\n",
    "œÄ(Œ∏')=‚à´œÄ(Œ∏)K(Œ∏'‚à£Œ∏)dŒ∏\n",
    "$$\n",
    "\n",
    "After long enough (and under some mild conditions) the chain converges to the stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6af0d8",
   "metadata": {},
   "source": [
    "### **Markov Chain Monte-Carlo (MCMC) Simulations**\n",
    "Bayes' Theorem requires us to compute:\n",
    "$\\mathbb{P}(\\theta|x) = \\frac{\\mathbb{P}(x|\\theta)\\mathbb{P}(\\theta)}{\\mathbb{P}(x)}$ \n",
    "\n",
    "However, this may create challenges: \n",
    "- $\\mathbb{P}(x) = \\int p(x \\mid \\theta)\\, p(\\theta)\\, d\\theta$ often cannot be solved analytically. Even computational methods fail in the case of many dimsensions because the integral is over all possible parameter values. Consider for instance the case where $\\theta \\in \\mathbb{R}^{1000}$ \n",
    "- In the worked example we used a conjugate prior meaning we could easily recognise the form of the posterior distribution. However, in general this will not be the case; we will not be able to recognise the form of the posterior distribution as coming from some common family of probability distributions.\n",
    "\n",
    "**Markov Chain Monte-Carlo (MCMC) Simulations** get around this issue by constructing a Markov chain which converges to the posterior rather than attempting to compute it directly. Once we can sample from the posterior, we can use sample statistics to approximate:\n",
    "- Posterior means\n",
    "- Posterior variances\n",
    "- Credible intervals\n",
    "- Predictive distributions\n",
    "\n",
    "The basic idea in MCMC is:\n",
    "1. Start at some initial value $\\theta_0$\n",
    "2. Propose small random moves\n",
    "3. Accept or reject moves based on how likely they are $\\mathbb{P}(x \\mid \\theta)\\mathbb{P}(\\theta)$\n",
    "4. Repeat thousands of times\n",
    "\n",
    "Once the chain has converged, we can treat subsequent samples as coming from the posterior, thus negating the need to compute the difficult integrals needed to perform Bayesian inference. Typically the values at the beginning of the chain are discarded to allow the chain to converge. This is controlled by a hyperparameter called the **burn-in**. \n",
    "\n",
    "For MCMC we set $\\pi(\\theta') = \\mathbb{P}(\\theta | x)$ so that instead of computing\n",
    "\n",
    "Instead of computing:\n",
    "$$\n",
    "‚à´ùëì(ùúÉ)\\mathbb{P}(ùúÉ‚à£ùë•)dŒ∏\n",
    "$$\n",
    "we simulate a chain with stationary distribution:\n",
    "$$\n",
    "\\mathbb{P}(Œ∏‚à£x)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
