{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe1e374",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Outliers are particularly problematic in linear regression due to the nature of the objective function. Linear regression tries to minimise the sum of the squared residuals; outliers may have very large residuals, which when squared make up a large proportion of the objective value. So linear models can be heavily influenced by the presence of outliers, to the detriment of their ability to predict non-outlier values. It is therefore important to identify outliers since they may distort the model.\n",
    "\n",
    "In order to detect outliers we first need to define what we mean by an outlier. Intuitively, defining an outlier as a prediction which is very far away from all other predictions seems sensible. This idea of being far away from the other predictions is called leverage. However high leverage alone does not necessarily imply a point is an outlier. That is because, even if a point has high leverage, it may still sit very close to the extrapolated regression line and so might not actually exert much influence on the model. We define a point's influence as its leverage x residual. This captures the idea that a point not only needs to be far from other predictions, but also far from the regression line (i.e. high residual) to distort the model and therefore be considered an outlier. \n",
    "\n",
    "More technically we define leverage and influence as follows:\n",
    "\n",
    "$$\n",
    "leverage_i = \\hat{y}_i - \\frac{1}{n}\\sum_{j=1}^n \\hat{y}_j\n",
    "$$\n",
    "\n",
    "So the leverage of a given point is the difference between its fitted value and the average of all fitted values. \n",
    "\n",
    "$$\n",
    "influence_i = leverage_i * residual_i = (\\hat{y}_i - \\frac{1}{n}\\sum_{j=1}^n \\hat{y}_j) * (\\hat{y}_i - y_i)\n",
    "$$\n",
    "\n",
    "Cook's distance is used to detect outliers. It works by comparing the fitted values of a model including the given point with the fitted values of a model fit with the given point removed. So it effecitvely measures how much a given point is effecting the model.\n",
    "\n",
    "$$\n",
    "Cook's\\;Distance_i = \\frac{1}{p \\hat{\\sigma}^2}\\sum_{j=1}^n (\\hat{y}_j - \\hat{y}_{j(i)})^2\n",
    "$$\n",
    "\n",
    "where\n",
    "- $p$: number of model parameters including the intercept  \n",
    "- $\\hat{\\sigma}^2$: estimated error variance  \n",
    "- $\\hat{y}_j$: fitted value using all data  \n",
    "- $\\hat{y}_{j(i)}$: fitted value when point i is omitted\n",
    "\n",
    "Note that it can also be expressed in terms of the residuals and leverage as follows:\n",
    "\n",
    "$$\n",
    "Cook's\\;Distance_i = \\frac{e_i^2}{p \\, \\sigma^2} \\cdot \\frac{h_{ii}}{(1 - h_{ii})^2}\n",
    "$$\n",
    "\n",
    "where\n",
    "- $e_i = y_i - \\hat{y_i}$ is the raw residual\n",
    "- $p$ is the number of model parameters including the intercept  \n",
    "- $\\hat{\\sigma}^2$ is the estimated error variance  \n",
    "- $h_{ii}$ is the leverage of point $i$\n",
    "\n",
    "Hence a point has a large Cook's Distanace if it both:\n",
    "- Usual in $X$ (i.e. high leverage $h_{ii}$) \n",
    "- Poorly fitted (i.e. large residual $e_i = y_i - \\hat{y_i}$)\n",
    "\n",
    "Generally points such that $Cook's\\;Distance_i > 1$ should be investigated. \n",
    "\n",
    "In the examples below, we demonstrate a point with high/low leverage/influence. In each case we plot the regression line with and without the given point and compute the Cook's Distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
